{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a9904e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67d383bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbs_path = \"/home/ubuntu/poppunk/poppunk_db\"\n",
    "prev_db = \"GPS_v9\"\n",
    "new_db = \"GPS_v9_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24aca9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_path(dbs_path, db_name, in_db, external):\n",
    "    path_list = [dbs_path]\n",
    "\n",
    "    if in_db:\n",
    "        path_list.append(db_name)\n",
    "\n",
    "    if external:\n",
    "        path_list.append(f\"{db_name}_external_clusters.csv\")\n",
    "    else:\n",
    "        path_list.append(f\"{db_name}_clusters.csv\")\n",
    "\n",
    "    return os.path.join(*path_list)\n",
    "\n",
    "\n",
    "def get_df(csv_path):\n",
    "    return pd.read_csv(csv_path, dtype=str, keep_default_na=False)\n",
    "\n",
    "\n",
    "def split_merged_clusters(clusters_series, external):\n",
    "    if external:\n",
    "        delimiter = \";\"\n",
    "    else:\n",
    "        delimiter = \"_\"\n",
    "    \n",
    "    return {int(val) for cluster in clusters_series.unique() for val in cluster.split(delimiter)}\n",
    "\n",
    "\n",
    "def get_merged_gpscs(df):\n",
    "    merged_gpscs = set()\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        # Skip 235;9 in merge cluster joint as it is an exceptional case\n",
    "        if row[\"GPSC\"] == \"235;9\":\n",
    "            continue\n",
    "        gpsc_splitted = set(row[\"GPSC\"].split(';'))\n",
    "        merge_history_splitted = set(row[\"merge_history\"].split(';'))\n",
    "\n",
    "        base_gpsc = min(gpsc_splitted, key=int)\n",
    "        if base_gpsc not in merge_history_splitted:\n",
    "            sys.exit(f\"Error:{base_gpsc} not found in merge_history {merge_history_splitted} of {row[\"sample\"]}\")\n",
    "\n",
    "        clustered_gpscs = gpsc_splitted.union(merge_history_splitted)\n",
    "\n",
    "        if len(clustered_gpscs) > 1:\n",
    "            merged_gpscs.add(frozenset(clustered_gpscs))\n",
    "\n",
    "    merged_gpscs = [set(merged_gpsc) for merged_gpsc in merged_gpscs]\n",
    "\n",
    "    new_merge = True\n",
    "\n",
    "    while new_merge:\n",
    "        new_merge = False\n",
    "        next_list = []\n",
    "        while merged_gpscs:\n",
    "            cur_merged_gpsc = merged_gpscs.pop()\n",
    "            for i, merged_gpsc in enumerate(next_list):\n",
    "                if cur_merged_gpsc.intersection(merged_gpsc):\n",
    "                    next_list[i] = cur_merged_gpsc.union(merged_gpsc)\n",
    "                    new_merge = True\n",
    "                    break\n",
    "            else:\n",
    "                next_list.append(cur_merged_gpsc)\n",
    "        merged_gpscs = next_list\n",
    "    \n",
    "    return merged_gpscs\n",
    "\n",
    "\n",
    "def get_merged_gpscs_info(merged_gpscs):\n",
    "    merged_gpscs_info_dict = dict()\n",
    "\n",
    "    for cluster in merged_gpscs:\n",
    "        base_gpsc = min(cluster, key=int)\n",
    "        merge_history = ';'.join(sorted(cluster, key=int))\n",
    "        for gpsc in cluster:\n",
    "            merged_gpscs_info_dict.update({gpsc: {'merge_history': merge_history, 'base_gpsc': base_gpsc}})\n",
    "    return merged_gpscs_info_dict\n",
    "\n",
    "\n",
    "def base_gpsc_merge_history_correction(df, merged_gpscs_info_dict):\n",
    "    df = df.copy()\n",
    "\n",
    "    exception_mask = df[\"GPSC\"] == \"235;9\"\n",
    "\n",
    "    base_gpsc = df[\"GPSC\"].str.split(\";\").apply(lambda gpsc: min(gpsc, key=int))\n",
    "\n",
    "    df[\"GPSC\"] = df[\"merge_history\"] = base_gpsc\n",
    "\n",
    "    gpsc_in_dict_mask = base_gpsc.isin(merged_gpscs_info_dict)\n",
    "\n",
    "    df.loc[gpsc_in_dict_mask, \"GPSC\"] = base_gpsc[gpsc_in_dict_mask].map(lambda gpsc: merged_gpscs_info_dict[gpsc][\"base_gpsc\"])\n",
    "    df.loc[gpsc_in_dict_mask, \"merge_history\"] = base_gpsc[gpsc_in_dict_mask].map(lambda gpsc: merged_gpscs_info_dict[gpsc][\"merge_history\"])\n",
    "\n",
    "    df.loc[exception_mask, \"GPSC\"] = df.loc[exception_mask, \"merge_history\"] = \"235;9\"\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d48532b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cluster ile paths and load into dataframes\n",
    "\n",
    "prev_db_poppunk_cluster_path = get_cluster_path(dbs_path, prev_db, in_db=True, external=False)\n",
    "prev_db_gpsc_path = get_cluster_path(dbs_path, prev_db, in_db=False, external=True)\n",
    "new_db_poppunk_cluster_path = get_cluster_path(dbs_path, new_db, in_db=True, external=False)\n",
    "new_db_gpsc_path = get_cluster_path(dbs_path, new_db, in_db=True, external=True)\n",
    "new_db_gpsc_output_path = get_cluster_path(dbs_path, new_db, in_db=False, external=True)\n",
    "\n",
    "df_prev_db_poppunk_cluster = get_df(prev_db_poppunk_cluster_path)\n",
    "df_prev_db_gpsc = get_df(prev_db_gpsc_path)\n",
    "df_new_db_poppunk_cluster = get_df(new_db_poppunk_cluster_path)\n",
    "df_new_db_gpsc = get_df(new_db_gpsc_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ade69cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous database GPS_v9:\n",
      "  PopPUNK Cluster range used : 1 - 1231\n",
      "  GPSC range used: 1 - 1122\n",
      "  The value difference between largest PopPUNK Cluster and GPSC: 109\n",
      "\n",
      "New database GPS_v9_1:\n",
      "  Number of samples with unassigned GPSC: 4\n",
      "  New PopPUNK Cluster range used: 1232 - 1234 (Length: 3)\n",
      "  New GPSC range assigned: 1123 - 1125 (Length: 3)\n"
     ]
    }
   ],
   "source": [
    "# Split all merged clusters in PopPUNK clusters and GPSC, assign GPSCs to new PopPUNK clusters, print information\n",
    "\n",
    "prev_gpscs_history_splitted = split_merged_clusters(df_prev_db_gpsc[\"merge_history\"], external=True)\n",
    "prev_poppunk_clusters_splitted = split_merged_clusters(df_prev_db_poppunk_cluster[\"Cluster\"], external=False)\n",
    "new_poppunk_clusters_splitted = split_merged_clusters(df_new_db_poppunk_cluster[\"Cluster\"], external=False)\n",
    "\n",
    "prev_poppunk_clusters_min, prev_poppunk_clusters_max  = min(prev_poppunk_clusters_splitted), max(prev_poppunk_clusters_splitted)\n",
    "prev_gpsc_history_min, prev_gpsc_history_max = min(prev_gpscs_history_splitted), max(prev_gpscs_history_splitted)\n",
    "\n",
    "diff_poppunk_clusters_and_gpsc_max = prev_poppunk_clusters_max - prev_gpsc_history_max\n",
    "\n",
    "new_poppunk_new_clusters = new_poppunk_clusters_splitted - prev_poppunk_clusters_splitted\n",
    "new_poppunk_new_clusters_min, new_poppunk_new_clusters_max = min(new_poppunk_new_clusters), max(new_poppunk_new_clusters)\n",
    "\n",
    "df_new_db_gpsc = df_new_db_gpsc.merge(df_new_db_poppunk_cluster.rename(columns={\"Taxon\": \"sample\"}), on=\"sample\", how=\"left\")\n",
    "\n",
    "gpsc_unassigned_mask = df_new_db_gpsc['GPSC'] == \"NA\"\n",
    "df_new_db_gpsc.loc[gpsc_unassigned_mask, \"GPSC\"] = df_new_db_gpsc.loc[gpsc_unassigned_mask, \"Cluster\"].astype(int) - diff_poppunk_clusters_and_gpsc_max\n",
    "\n",
    "new_gpsc_min = new_poppunk_new_clusters_min - diff_poppunk_clusters_and_gpsc_max\n",
    "new_gpsc_max = new_poppunk_new_clusters_max - diff_poppunk_clusters_and_gpsc_max\n",
    "\n",
    "print(f\"Previous database {prev_db}:\")\n",
    "print(f\"  PopPUNK Cluster range used : {prev_poppunk_clusters_min} - {prev_poppunk_clusters_max}\")\n",
    "print(f\"  GPSC range used: {prev_gpsc_history_min} - {prev_gpsc_history_max}\")\n",
    "print(f\"  The value difference between largest PopPUNK Cluster and GPSC: {diff_poppunk_clusters_and_gpsc_max}\")\n",
    "print()\n",
    "print(f\"New database {new_db}:\")\n",
    "print(f\"  Number of samples with unassigned GPSC: {gpsc_unassigned_mask.sum()}\")\n",
    "print(f\"  New PopPUNK Cluster range used: {new_poppunk_new_clusters_min} - {new_poppunk_new_clusters_max} (Length: {new_poppunk_new_clusters_max - new_poppunk_new_clusters_min + 1})\")\n",
    "print(f\"  New GPSC range assigned: {new_gpsc_min} - {new_gpsc_max} (Length: {new_gpsc_max - new_gpsc_min + 1})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3f0bed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add merge history from previous database and assign current GPSC to those without history\n",
    "df_new_db_gpsc = df_new_db_gpsc[[\"sample\", \"GPSC\"]].merge(df_prev_db_gpsc[[\"sample\", \"merge_history\"]], on=\"sample\", how=\"left\")\n",
    "df_new_db_gpsc[\"merge_history\"] = df_new_db_gpsc[\"merge_history\"].fillna(df_new_db_gpsc[\"GPSC\"])\n",
    "df_new_db_gpsc = df_new_db_gpsc.astype(str)\n",
    "\n",
    "# Get all merged GPSCs and ensure all intersected sets are fully joint\n",
    "merged_gpscs = get_merged_gpscs(df_new_db_gpsc)\n",
    "\n",
    "# Generate information for merged GPSCs\n",
    "merged_gpscs_info_dict = get_merged_gpscs_info(merged_gpscs)\n",
    "\n",
    "# Ensure base GPSC and correct fully joint merge history are used (235;9 is an exception)\n",
    "df_new_db_gpsc = base_gpsc_merge_history_correction(df_new_db_gpsc, merged_gpscs_info_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3970c7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output updated GPSC assignmnet\n",
    "df_new_db_gpsc.to_csv(new_db_gpsc_output_path, index=False)\n",
    "\n",
    "\n",
    "# Remove oudated GPSC Designation file and reference-only database in the new database \n",
    "os.remove(new_db_gpsc_path)\n",
    "for f in glob.glob(os.path.join(dbs_path, new_db, f\"{new_db}.refs*\")):\n",
    "    os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec93f695",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
